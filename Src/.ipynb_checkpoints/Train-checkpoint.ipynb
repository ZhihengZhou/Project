{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from layer import *\n",
    "from network import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(dir_='../data/npy'):\n",
    "    x_train = np.load(os.path.join(dir_, 'x_train.npy'))\n",
    "    x_test = np.load(os.path.join(dir_, 'x_test.npy'))\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMAGE_SIZE2 = 160\n",
    "IMAGE_SIZE1 = 256\n",
    "LOCAL_SIZE = 64\n",
    "HOLE_MIN = 24\n",
    "HOLE_MAX = 48\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 16\n",
    "PRETRAIN_EPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [BATCH_SIZE, IMAGE_SIZE1, IMAGE_SIZE2, 3])\n",
    "mask = tf.placeholder(tf.float32, [BATCH_SIZE, IMAGE_SIZE1, IMAGE_SIZE2, 1])\n",
    "local_x = tf.placeholder(tf.float32, [BATCH_SIZE, LOCAL_SIZE, LOCAL_SIZE, 3])\n",
    "global_completion = tf.placeholder(tf.float32, [BATCH_SIZE, IMAGE_SIZE1, IMAGE_SIZE2, 3])\n",
    "local_completion = tf.placeholder(tf.float32, [BATCH_SIZE, LOCAL_SIZE, LOCAL_SIZE, 3])\n",
    "is_training = tf.placeholder(tf.bool, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network(x, mask, local_x, global_completion, local_completion, is_training, batch_size=BATCH_SIZE)\n",
    "\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "epoch = tf.Variable(0, name='epoch', trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "\n",
    "g_train_op = opt.minimize(model.g_loss, global_step=global_step, var_list=model.g_variables)\n",
    "\n",
    "d_train_op = opt.minimize(model.d_loss, global_step=global_step, var_list=model.d_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = load()\n",
    "\n",
    "# Seperate data\n",
    "train_original = np.array([i[0] for i in train_data])\n",
    "train_masked = np.array([i[1] for i in train_data])\n",
    "mask_bounds = np.array([i[2] for i in train_data])\n",
    "\n",
    "test_original = np.array([i[0] for i in test_data])\n",
    "test_masked = np.array([i[1] for i in test_data])\n",
    "test_mask_bounds = np.array([i[2] for i in test_data])\n",
    "# x_train = np.array([a / 127.5 - 1 for a in x_train])\n",
    "# x_test = np.array([a / 127.5 - 1 for a in x_test])\n",
    "\n",
    "step_num = int(len(train_data) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(bounds):\n",
    "    points = []\n",
    "    mask = []\n",
    "    for b in bounds:\n",
    "        \n",
    "        mid_y = (b[0] + b[2])/2\n",
    "        mid_x = (b[1] + b[3])/2\n",
    "        \n",
    "        x1 = int(mid_x - LOCAL_SIZE/2)\n",
    "        if x1 < 0:\n",
    "            x1 = 0\n",
    "        elif x1 > IMAGE_SIZE1 - LOCAL_SIZE:\n",
    "            x1 = IMAGE_SIZE1 - LOCAL_SIZE\n",
    "            \n",
    "        y1 = int(mid_y - LOCAL_SIZE/2)\n",
    "        if y1 < 0:\n",
    "            y1 = 0\n",
    "        elif y1 > IMAGE_SIZE2 - LOCAL_SIZE:\n",
    "            y1 = IMAGE_SIZE2 - LOCAL_SIZE\n",
    "            \n",
    "        x2, y2 = np.array([x1, y1]) + LOCAL_SIZE\n",
    "        points.append([x1, y1, x2, y2])\n",
    "\n",
    "        p1 = b[0]\n",
    "        q1 = b[1]\n",
    "        p2 = b[2]\n",
    "        q2 = b[3]\n",
    "        \n",
    "        m = np.zeros((IMAGE_SIZE1, IMAGE_SIZE2, 1), dtype=np.uint8)\n",
    "        m[q1:q2 + 1, p1:p2 + 1] = 1\n",
    "        mask.append(m)\n",
    "\n",
    "\n",
    "    return np.array(points), np.array(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    sess.run(tf.assign(epoch, tf.add(epoch, 1)))\n",
    "    print('epoch: {}'.format(sess.run(epoch)))\n",
    "\n",
    "    np.random.shuffle(train_data)\n",
    "\n",
    "    # Completion \n",
    "    if sess.run(epoch) <= PRETRAIN_EPOCH:\n",
    "        g_loss_value = 0\n",
    "        for i in tqdm.tqdm(range(step_num)):\n",
    "            train_batch = train_data[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
    "            x_batch = np.array([i[0] for i in train_batch])\n",
    "            points_batch, mask_batch = get_points([i[2] for i in train_batch])\n",
    "\n",
    "            _, g_loss = sess.run([g_train_op, model.g_loss], feed_dict={x: x_batch, mask: mask_batch, is_training: True})\n",
    "            g_loss_value += g_loss\n",
    "\n",
    "        print('Completion loss: {}'.format(g_loss_value))\n",
    "\n",
    "        np.random.shuffle(test_data) \n",
    "        test_batch = test_data[:BATCH_SIZE]\n",
    "        x_batch = np.array([i[0] for i in test_batch])\n",
    "        points_batch, mask_batch = get_points([i[2] for i in test_batch])\n",
    "        \n",
    "        completion = sess.run(model.completion, feed_dict={x: x_batch, mask: mask_batch, is_training: False})\n",
    "        sample = np.array((completion[0] + 1) * 127.5, dtype=np.uint8)\n",
    "        cv2.imwrite('./output/{}.jpg'.format(\"{0:06d}\".format(sess.run(epoch))), cv2.cvtColor(sample, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, './backup/latest', write_meta_graph=False)\n",
    "        if sess.run(epoch) == PRETRAIN_EPOCH:\n",
    "            saver.save(sess, './backup/pretrained', write_meta_graph=False)\n",
    "\n",
    "\n",
    "    # Discrimitation\n",
    "    else:\n",
    "        g_loss_value = 0\n",
    "        d_loss_value = 0\n",
    "        for i in tqdm.tqdm(range(1)):\n",
    "            train_batch = train_data[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
    "            x_batch = np.array([i[0] for i in train_batch])\n",
    "            points_batch, mask_batch = get_points([i[2] for i in train_batch])\n",
    "\n",
    "            _, g_loss, completion = sess.run([g_train_op, model.g_loss, model.completion], feed_dict={x: x_batch, mask: mask_batch, is_training: True})\n",
    "            g_loss_value += g_loss\n",
    "\n",
    "            local_x_batch = []\n",
    "            local_completion_batch = []\n",
    "            for i in range(BATCH_SIZE):\n",
    "                x1, y1, x2, y2 = points_batch[i]\n",
    "                local_x_batch.append(x_batch[i][x1:x2, y1:y2, :])\n",
    "                local_completion_batch.append(completion[i][x1:x2, y1:y2, :])\n",
    "            local_x_batch = np.array(local_x_batch)\n",
    "            local_completion_batch = np.array(local_completion_batch)\n",
    "\n",
    "            _, d_loss = sess.run(\n",
    "                [d_train_op, model.d_loss], \n",
    "                feed_dict={x: x_batch, mask: mask_batch, local_x: local_x_batch, global_completion: completion, local_completion: local_completion_batch, is_training: True})\n",
    "            d_loss_value += d_loss\n",
    "\n",
    "        print('Completion loss: {}'.format(g_loss_value))\n",
    "        print('Discriminator loss: {}'.format(d_loss_value))\n",
    "\n",
    "        np.random.shuffle(test_data) \n",
    "        test_batch = test_data[:BATCH_SIZE]\n",
    "        x_batch = np.array([i[0] for i in test_batch])\n",
    "        points_batch, mask_batch = get_points([i[2] for i in test_batch])\n",
    "        \n",
    "        completion = sess.run(model.completion, feed_dict={x: x_batch, mask: mask_batch, is_training: False})\n",
    "        sample = np.array((completion[0] + 1) * 127.5, dtype=np.uint8)\n",
    "        cv2.imwrite('./output/{}.jpg'.format(\"{0:06d}\".format(sess.run(epoch))), cv2.cvtColor(sample, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, './backup/latest', write_meta_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
